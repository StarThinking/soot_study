$r16
r2
dfs.namenode.legacy-oiv-image.dir
r64
r3
r3
$r29
r1
$r15
hadoop.zk.address
dfs.encrypt.data.transfer.cipher.suites
dfs.namenode.shared.edits.dir
dfs.encrypt.data.overwrite.downstream.new.qop
dfs.nameservice.id
dfs.encrypt.data.transfer.cipher.suites
dfs.encrypt.data.transfer.cipher.suites
r1
dfs.federation.router.store.driver.fs.path
dfs.federation.router.store.driver.file.directory
r5
httpfs.fs.user
httpfs.fs.user
io.compression.codecs
r3
r2
r2
r1
r1
bind.address
hadoop.http.temp.dir
r2
r2
r2
r2
r2
r23
ha.zookeeper.quorum
r1
dfs.nameservices
r1
r4
r3
ssl.server.exclude.cipher.list
ssl.server.truststore.location
r3
dfs.client.cache.drop.behind.writes
dfs.client.cache.readahead
dfs.client.cache.drop.behind.reads
$r7
r1
r1
r1
r1
r1
r1
r1
r1
r1
r1
r1
r1
r1
dfs.datanode.data.dir
$r11
tmpjars
r1
r1
dfs.encrypt.data.transfer.algorithm
dfs.data.transfer.protection
$r7
fs.permissions.umask-mode
r1
dfs.web.authentication.kerberos.keytab
r3
ssl.server.exclude.cipher.list
ssl.server.truststore.location
ssl.server.keystore.location
r4
r1
dfs.provided.aliasmap.inmemory.dnrpc-address
dfs.provided.aliasmap.inmemory.dnrpc-address
r3
dfs.provided.aliasmap.text.codec
dfs.provided.aliasmap.leveldb.path
r3
r1
dfs.ha.namenode.id
dfs.ha.namenode.id
dfs.nameservice.id
$r9
$r7
dfs.namenode.rpc-address
dfs.namenode.rpc-address
dfs.namenode.shared.edits.dir
r10
$r5
dfs.metrics.session-id
hadoop.security.kerberos.ticket.cache.path
r1
r1
r7
r3
hadoop.security.dns.nameserver
hadoop.security.dns.interface
hadoop.kerberos.min.seconds.before.relogin
hadoop.token.files
r34
$r18
r1
dfs.journalnode.edits.dir "/tmp/hadoop/dfs/journalnode/"
dfs.journalnode.edits.dir.perm "700"
dfs.journalnode.edits.dir "/tmp/hadoop/dfs/journalnode/"
r1 r2
dfs.datanode.data.dir.perm "700"
dfs.provided.storage.id "DS-PROVIDED"
hadoop.zk.acl "world:anyone:rwcda"
dfs.federation.router.store.driver.zk.parent-path "/hdfs-federation"
dfs.disk.balancer.plan.valid.interval "1d"
hadoop.security.crypto.jceks.key.serialfilter "java.lang.Enum;java.security.KeyRep;java.security.KeyRep$Type;javax.crypto.spec.SecretKeySpec;org.apache.hadoop.crypto.key.JavaKeyStoreProvider$KeyMetadata;!*"
dfs.storage.policy.satisfier.mode $r4
dfs.hosts.exclude ""
dfs.hosts ""
dfs.hosts ""
hadoop.security.crypto.cipher.suite "AES/CTR/NoPadding"
dfs.storage.policy.satisfier.mode $r8
dfs.namenode.storage.dir.perm "700"
dfs.namenode.storage.dir.perm "700"
ha.zookeeper.parent-znode "/hadoop-ha"
$r44 r9
r15 r8
$r32 r6
$r25 r5
$r23 ""
r7 "*"
security.service.authorization.default.acl.blocked ""
security.service.authorization.default.acl "*"
fs.defaultFS "file:///"
dfs.image.compression.codec "org.apache.hadoop.io.compress.DefaultCodec"
ha.zookeeper.acl "world:anyone:rwcda"
hadoop.ssl.hostname.verifier "DEFAULT"
dfs.namenode.kerberos.principal ""
dfs.datanode.startup $r3
ssl.server.truststore.type "jks"
ssl.server.keystore.type "jks"
r3 $r18
hadoop.user.group.static.mapping.overrides "dr.who=;"
dfs.client.block.write.replace-datanode-on-failure.policy "DEFAULT"
dfs.client.context "default"
hadoop.security.sensitive-config-keys $r7
hadoop.ssl.server.conf "ssl-server.xml"
hadoop.ssl.client.conf "ssl-client.xml"
dfs.datanode.kerberos.principal ""
r1 r2
dfs.user.home.dir.prefix "/user"
dfs.datanode.kerberos.principal ""
dfs.checksum.combine.mode "MD5MD5CRC"
mapreduce.task.attempt.id "NONMAPREDUCE"
dfs.https.server.keystore.resource "ssl-server.xml"
ssl.server.truststore.type "jks"
ssl.server.keystore.type "jks"
dfs.cluster.administrators " "
dfs.journalnode.http-address "0.0.0.0:8480"
dfs.journalnode.https-address "0.0.0.0:8481"
dfs.datatransfer.client.variableBlackList.file r5
dfs.datatransfer.client.fixedBlackList.file r4
dfs.datatransfer.server.variableBlackList.file "/etc/hadoop/blackList"
dfs.datatransfer.server.fixedBlackList.file "/etc/hadoop/fixedBlackList"
dfs.datatransfer.client.variablewhitelist.file r5
dfs.datatransfer.client.fixedwhitelist.file r4
dfs.datatransfer.server.variablewhitelist.file "/etc/hadoop/whitelist"
dfs.datatransfer.server.fixedwhitelist.file "/etc/hadoop/fixedwhitelist"
dfs.provided.aliasmap.text.delimiter "
dfs.provided.aliasmap.text.read.file "file:///tmp/blocks.csv"
dfs.provided.aliasmap.text.delimiter "
dfs.provided.aliasmap.text.write.dir $r4
dfs.webhdfs.acl.provider.permission.pattern "^(default:
dfs.webhdfs.user.provider.user.pattern "^[A-Za-z_][A-Za-z0-9._-]*[$]?$"
fs.viewfs.rename.strategy $r9
hadoop.kerberos.kinit.command "kinit"
dfs.namenode.startup $r2
dfs.http.policy $r3
r1 r2
dfs.namenode.kerberos.principal ""
dfs.namenode.kerberos.principal ""
dfs.namenode.kerberos.principal ""
dfs.namenode.kerberos.principal ""
dfs.namenode.kerberos.principal ""
r2 r3
hadoop.rpc.socket.factory.class.default "org.apache.hadoop.net.StandardSocketFactory"
dfs.journalnode.rpc-address "0.0.0.0:8485"
dfs.checksum.type "CRC32C"
r1 r2
hadoop.security.authentication "simple"
hadoop.security.auth_to_local.mechanism "hadoop"
hadoop.security.auth_to_local r8
fs.defaultFS "file:///"
dfs.mover.address "0.0.0.0:0"
dfs.balancer.address "0.0.0.0:0"
r2 $r8
dfs.namenode.kerberos.principal ""
dfs.namenode.kerberos.principal ""
