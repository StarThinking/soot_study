dfs.block.access.key.update.interval 600L
dfs.block.access.token.enable false
dfs.block.access.token.lifetime 600L
dfs.block.access.token.protobuf.enable false
dfs.block.invalidate.limit 1000
dfs.block.misreplication.processing.limit 10000
dfs.block.placement.ec.classname $r11, class "Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy;"
dfs.block.replicator.classname $r7, class "Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy;"
dfs.blocksize 134217728L
dfs.bytes-per-checksum 512
dfs.checksum.combine.mode "MD5MD5CRC"
dfs.checksum.type "CRC32C"
dfs.client.block.write.locateFollowingBlock.initial.delay.ms 400
dfs.client.block.write.locateFollowingBlock.retries 5
dfs.client.block.write.replace-datanode-on-failure.best-effort false
dfs.client.block.write.replace-datanode-on-failure.enable true
dfs.client.block.write.replace-datanode-on-failure.min-replication 0
dfs.client.block.write.replace-datanode-on-failure.policy "DEFAULT"
dfs.client.block.write.retries 3
dfs.client.cached.conn.retry 3
dfs.client.cache.drop.behind.reads
dfs.client.cache.drop.behind.reads false
dfs.client.cache.drop.behind.writes
dfs.client.cache.drop.behind.writes false
dfs.client.cache.readahead
dfs.client.cache.readahead 0L
dfs.client.context "default"
dfs.client.datanode-restart.timeout 30L, $r7
dfs.client.domain.socket.data.traffic false
dfs.client.failover.max.attempts 15
dfs.client.failover.sleep.base.millis 500
dfs.client.failover.sleep.max.millis 15000
dfs.client.hedged.read.threadpool.size 0
dfs.client.hedged.read.threshold.millis 500L
dfs.client.https.need-auth false
dfs.client.key.provider.cache.expiry $l3
dfs.client.local.interfaces
dfs.client.max.block.acquire.failures 3
dfs.client.mmap.cache.size 256
dfs.client.mmap.cache.timeout.ms 3600000L
dfs.client.mmap.enabled true
dfs.client.mmap.retry.timeout.ms 300000L
dfs.client.read.prefetch.size $l23
dfs.client.read.shortcircuit.buffer.size 1048576
dfs.client.read.shortcircuit.metrics.sampling.percentage 0
dfs.client.read.short.circuit.replica.stale.threshold.ms 1800000L
dfs.client.read.shortcircuit.skip.checksum false
dfs.client.read.shortcircuit.streams.cache.expiry.ms 300000L
dfs.client.read.shortcircuit.streams.cache.size 256
dfs.client.read.striped.threadpool.size 18
dfs.client.replica.accessor.builder.classes
dfs.client.retry.interval-ms.get-last-block-length 4000
dfs.client.retry.max.attempts 10
dfs.client.retry.times.get-last-block-length 3
dfs.client.retry.window.base 3000
dfs.client.server-defaults.validity.period.ms $l7
dfs.client.slow.io.warning.threshold.ms 30000L
dfs.client.socketcache.capacity 16
dfs.client.socketcache.expiryMsec 3000L
dfs.client.socket.send.buffer.size 0
dfs.client.socket-timeout 60000
dfs.client.test.drop.namenode.response.number 0
dfs.client.use.datanode.hostname false
dfs.client.use.legacy.blockreader.local false
dfs.client.write.byte-array-manager.count-limit 2048
dfs.client.write.byte-array-manager.count-reset-time-period-ms 10000L
dfs.client.write.byte-array-manager.count-threshold 128
dfs.client.write.byte-array-manager.enabled false
dfs.client.write.exclude.nodes.cache.expiry.interval.millis 600000L
dfs.client.write.max-packets-in-flight 80
dfs.client-write-packet-size 65536
dfs.cluster.administrators " "
dfs.content-summary.limit 5000
dfs.content-summary.sleep-microsec 500L
dfs.corruptfilesreturned.max 500
dfs.datanode.address "0.0.0.0:9866"
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction 0.75F
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold 10737418240L
dfs.datanode.block.id.layout.upgrade.threads 12
dfs.datanode.block-pinning.enabled false
dfs.datanode.cached-dfsused.check.interval.ms 600000L
dfs.datanode.cache.revocation.polling.ms 500L
dfs.datanode.cache.revocation.timeout.ms 900000L
dfs.datanode.data.dir
dfs.datanode.data.dir.perm "700"
dfs.datanode.directoryscan.interval 21600L, $r3
dfs.datanode.directoryscan.interval 21600L, $r8
dfs.datanode.directoryscan.threads 1
dfs.datanode.directoryscan.throttle.limit.ms.per.sec 1000
dfs.datanode.duplicate.replica.deletion true
dfs.datanode.du.reserved.calculator $r2, class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator;"
dfs.datanode.ec.reconstruction.stripedread.buffer.size 65536
dfs.datanode.ec.reconstruction.stripedread.timeout.millis 5000
dfs.datanode.enable.fileio.fault.injection false
dfs.datanode.fileio.profiling.sampling.percentage 0
dfs.datanode.fsdatasetcache.max.threads.per.volume 4
dfs.datanode.fsdataset.factory class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetFactory;", class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi$Factory;"
dfs.datanode.fsdataset.volume.choosing.policy class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/RoundRobinVolumeChoosingPolicy;", class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/VolumeChoosingPolicy;"
dfs.datanode.http.address "0.0.0.0:9864"
dfs.datanode.https.address "0.0.0.0:9865"
dfs.datanode.ipc.address "0.0.0.0:9867"
dfs.datanode.lazywriter.interval.sec 60
dfs.datanode.outliers.report.interval "30m", $r4
dfs.datanode.outliers.report.interval "30m", $r6
dfs.datanode.parallel.volumes.load.threads.num i0
dfs.datanode.peer.stats.enabled false
dfs.datanode.ram.disk.replica.tracker $r4, class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaTracker;"
dfs.datanode.socket.write.timeout 480000
dfs.datanode.startup $r3
dfs.datanode.volumes.replica-add.threadpool.size i1
dfs.datatransfer.client.fixedBlackList.file r4
dfs.datatransfer.client.fixedwhitelist.file r4
dfs.data.transfer.client.tcpnodelay true
dfs.datatransfer.client.variableBlackList.cache.secs 3600L
dfs.datatransfer.client.variableBlackList.enable false
dfs.datatransfer.client.variableBlackList.file r5
dfs.datatransfer.client.variablewhitelist.cache.secs 3600L
dfs.datatransfer.client.variablewhitelist.enable false
dfs.datatransfer.client.variablewhitelist.file r5
dfs.data.transfer.protection
dfs.data.transfer.saslproperties.resolver.class r8, class "Lorg/apache/hadoop/security/SaslPropertiesResolver;"
dfs.datatransfer.server.fixedBlackList.file "/etc/hadoop/fixedBlackList"
dfs.datatransfer.server.fixedwhitelist.file "/etc/hadoop/fixedwhitelist"
dfs.datatransfer.server.variableBlackList.cache.secs 3600L
dfs.datatransfer.server.variableBlackList.enable false
dfs.datatransfer.server.variableBlackList.file "/etc/hadoop/blackList"
dfs.datatransfer.server.variablewhitelist.cache.secs 3600L
dfs.datatransfer.server.variablewhitelist.enable false
dfs.datatransfer.server.variablewhitelist.file "/etc/hadoop/whitelist"
dfs.disk.balancer.block.tolerance.percent 10L
dfs.disk.balancer.enabled true
dfs.disk.balancer.max.disk.errors 5L
dfs.disk.balancer.max.disk.throughputInMBperSec 10
dfs.disk.balancer.max.disk.throughputInMBperSec 10L
dfs.disk.balancer.plan.valid.interval "1d"
dfs.disk.balancer.plan.valid.interval "1d", $r10
dfs.domain.socket.disable.interval.seconds 600L
dfs.domain.socket.path ""
dfs.edit.log.transfer.bandwidthPerSec 0L
dfs.edit.log.transfer.timeout 30000
dfs.encrypt.data.transfer.algorithm
dfs.encrypt.data.transfer.cipher.key.bitlength 128
dfs.encrypt.data.transfer.cipher.suites
dfs.encrypt.data.transfer false
dfs.federation.router.store.driver.file.directory
dfs.federation.router.store.driver.fs.path
dfs.federation.router.store.driver.zk.parent-path "/hdfs-federation"
dfs.federation.router.store.serializer $r2, class "Lorg/apache/hadoop/hdfs/server/federation/store/driver/StateStoreSerializer;"
dfs.ha.automatic-failover.enabled false
dfs.ha.log-roll.period 120L, $r7
dfs.ha.log-roll.rpc.timeout 20000
dfs.ha.namenode.id
dfs.ha.standby.checkpoints true
dfs.ha.tail-edits.in-progress false
dfs.ha.tail-edits.max-txns-per-lock 9223372036854775807L
dfs.ha.tail-edits.namenode-retries 3
dfs.ha.tail-edits.period 60L, $r9
dfs.ha.tail-edits.rolledits.timeout 60
dfs.ha.zkfc.nn.http.timeout.ms 20000
dfs.ha.zkfc.port 8019
dfs.heartbeat.interval 3L, $r31
dfs.heartbeat.interval 3L, $r35
dfs.heartbeat.interval 3L, $r5
dfs.heartbeat.interval 3L, $r6
dfs.heartbeat.interval r3, $r8
dfs.hosts ""
dfs.hosts.exclude ""
dfs.http.client.failover.max.attempts 15
dfs.http.client.failover.sleep.base.millis 500
dfs.http.client.failover.sleep.max.millis 15000
dfs.http.client.retry.max.attempts 10
dfs.http.policy $r3
dfs.https.server.keystore.resource "ssl-server.xml"
dfs.image.compress false
dfs.image.compression.codec "org.apache.hadoop.io.compress.DefaultCodec"
dfs.image.string-tables.expanded false
dfs.image.transfer.bandwidthPerSec 0L
dfs.image.transfer-bootstrap-standby.bandwidthPerSec 0L
dfs.image.transfer.chunksize 65536
dfs.image.transfer.timeout 60000
dfs.internal.nameservices
dfs.journalnode.edits.dir "/tmp/hadoop/dfs/journalnode/"
dfs.journalnode.enable.sync true
dfs.journalnode.sync.interval 120000L
dfs.lock.suppress.warning.interval 10000L, $r13
dfs.lock.suppress.warning.interval 10000L, $r14
dfs.ls.limit 1000
dfs.metrics.percentiles.intervals
dfs.metrics.session-id
dfs.namenode.accesstime.precision 3600000L
dfs.namenode.acls.enabled false
dfs.namenode.audit.log.async false
dfs.namenode.audit.log.debug.cmdlist
dfs.namenode.audit.loggers
dfs.namenode.audit.log.token.tracking.id false
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction 0.6F
dfs.namenode.avoid.read.stale.datanode false
dfs.namenode.avoid.write.stale.datanode false
dfs.namenode.block.deletion.increment 1000
dfs.namenode.block-placement-policy.default.prefer-local-node true
dfs.namenode.blocks.per.postponedblocks.rescan 10000L
dfs.namenode.checkpoint.check.period 60L, $r2
dfs.namenode.checkpoint.check.quiet-multiplier 1.5
dfs.namenode.checkpoint.dir
dfs.namenode.checkpoint.edits.dir
dfs.namenode.checkpoint.max-retries 3
dfs.namenode.checkpoint.period 3600L, $r3
dfs.namenode.checkpoint.txns 1000000L
dfs.namenode.datanode.registration.ip-hostname-check true
dfs.namenode.delegation.key.update-interval 86400000L
dfs.namenode.delegation.token.always-use false
dfs.namenode.delegation.token.max-lifetime 604800000L
dfs.namenode.delegation.token.renew-interval 86400000L
dfs.namenode.ec.policies.max.cellsize 4194304
dfs.namenode.ec.system.default.policy "RS-6-3-1024k"
dfs.namenode.edekcacheloader.initial.delay.ms 3000
dfs.namenode.edekcacheloader.interval.ms 1000
dfs.namenode.edit.log.autoroll.check.interval.ms 300000
dfs.namenode.edit.log.autoroll.multiplier.threshold 2.0F
dfs.namenode.edits.asynclogging true
dfs.namenode.edits.dir.minimum 1
dfs.namenode.edits.noeditlogchannelflush false
dfs.namenode.enable.retrycache true
dfs.namenode.file.close.num-committed-allowed 0
dfs.namenode.fs-limits.max-blocks-per-file 10000L
dfs.namenode.fs-limits.max-component-length 255
dfs.namenode.fs-limits.max-directory-items 1048576
dfs.namenode.fs-limits.max-xattr-size 16384
dfs.namenode.fs-limits.max-xattrs-per-inode 32
dfs.namenode.fs-limits.min-block-size 1048576L
dfs.namenode.fslock.fair true
dfs.namenode.full.block.report.lease.length.ms 300000L
dfs.namenode.heartbeat.recheck-interval 300000
dfs.namenode.hosts.provider.classname class "Lorg/apache/hadoop/hdfs/server/blockmanagement/HostFileManager;", class "Lorg/apache/hadoop/hdfs/server/blockmanagement/HostConfigManager;"
dfs.namenode.inode.attributes.provider.bypass.users $r4
dfs.namenode.inode.attributes.provider.class null, class "Lorg/apache/hadoop/hdfs/server/namenode/INodeAttributeProvider;"
dfs.namenode.inotify.max.events.per.rpc 1000
dfs.namenode.invalidate.work.pct.per.iteration 0.32F
dfs.namenode.kerberos.principal ""
dfs.namenode.lazypersist.file.scrub.interval.sec 300
dfs.namenode.lease-recheck-interval-ms 2000L
dfs.namenode.legacy-oiv-image.dir
dfs.namenode.list.cache.directives.num.responses 100
dfs.namenode.list.cache.pools.num.responses 100
dfs.namenode.list.encryption.zones.num.responses 100
dfs.namenode.list.openfiles.num.responses 1000
dfs.namenode.list.reencryption.status.num.responses 100
dfs.namenode.lock.detailed-metrics.enabled false
dfs.namenode.maintenance.replication.min 1
dfs.namenode.max-corrupt-file-blocks-returned 100
dfs.namenode.max.extra.edits.segments.retained 10000
dfs.namenode.max.full.block.report.leases 6
dfs.namenode.max-lock-hold-to-release-lease-ms 25L
dfs.namenode.max-num-blocks-to-log 1000L
dfs.namenode.max.objects 0L
dfs.namenode.name.cache.threshold 10
dfs.namenode.name.dir.restore false
dfs.namenode.num.checkpoints.retained 2
dfs.namenode.num.extra.edits.retained 1000000L
dfs.namenode.path.based.cache.block.map.allocation.percent 0.25F
dfs.namenode.path.based.cache.refresh.interval.ms 30000L
dfs.namenode.path.based.cache.retry.interval.ms 30000L
dfs.namenode.posix.acl.inheritance.enabled true
dfs.namenode.provided.enabled false
dfs.namenode.quota.init-threads 4
dfs.namenode.read-lock-reporting-threshold-ms 5000L
dfs.namenode.reconstruction.pending.timeout-sec 300
dfs.namenode.redundancy.considerLoad.factor 2.0
dfs.namenode.redundancy.considerLoad true
dfs.namenode.redundancy.interval.seconds 3L, $r34
dfs.namenode.reencrypt.batch.size 1000
dfs.namenode.reencrypt.edek.threads 10
dfs.namenode.reencrypt.sleep.interval "1m", $r11
dfs.namenode.reencrypt.throttle.limit.handler.ratio 1.0
dfs.namenode.reencrypt.throttle.limit.updater.ratio 1.0
dfs.namenode.reject-unresolved-dn-topology-mapping false
dfs.namenode.replication.max-streams 2
dfs.namenode.replication.max-streams-hard-limit 4
dfs.namenode.replication.min 1
dfs.namenode.replication.work.multiplier.per.iteration 2
dfs.namenode.replqueue.threshold-pct $f1
dfs.namenode.resource.check.interval 5000L
dfs.namenode.retrycache.expirytime.millis 600000L
dfs.namenode.retrycache.heap.percent 0.03F
dfs.namenode.rpc-address
dfs.namenode.safemode.extension 30000L, $r10
dfs.namenode.safemode.min.datanodes 0
dfs.namenode.safemode.replication.min i0
dfs.namenode.safemode.threshold-pct 0.999F
dfs.namenode.secondary.http-address "0.0.0.0:9868"
dfs.namenode.secondary.https-address "0.0.0.0:9869"
dfs.namenode.servicerpc-address
dfs.namenode.shared.edits.dir
dfs.namenode.snapshot.capture.openfiles false
dfs.namenode.snapshotdiff.allow.snap-root-descendant true
dfs.namenode.snapshotdiff.listing.limit 1000
dfs.namenode.snapshot.max.limit 65536
dfs.namenode.snapshot.skip.capture.accesstime-only-change false
dfs.namenode.snapshot.skiplist.interval 10
dfs.namenode.snapshot.skiplist.max.levels 0
dfs.namenode.stale.datanode.interval 30000L
dfs.namenode.stale.datanode.minimum.interval 3
dfs.namenode.startup.delay.block.deletion.sec 0L
dfs.namenode.startup $r2
dfs.namenode.storageinfo.defragment.interval.ms 600000L
dfs.namenode.storageinfo.defragment.ratio 0.75
dfs.namenode.storageinfo.defragment.timeout.ms 4L
dfs.namenode.tolerate.heartbeat.multiplier 4
dfs.namenode.top.enabled true
dfs.namenode.top.num.users
dfs.namenode.top.num.users 10
dfs.namenode.top.window.num.buckets
dfs.namenode.top.window.num.buckets 10
dfs.namenode.top.windows.minutes
dfs.namenode.top.windows.minutes $r3
dfs.namenode.upgrade.domain.factor 3
dfs.namenode.write-lock-reporting-threshold-ms 5000L
dfs.namenode.write.stale.datanode.ratio 0.5F
dfs.namenode.xattrs.enabled true
dfs.nameservice.id
dfs.nameservices
dfs.net.topology.impl $r2, class "Lorg/apache/hadoop/hdfs/net/DFSNetworkTopology;"
dfs.permissions.enabled true
dfs.permissions.superusergroup "supergroup"
dfs.provided.aliasmap.class class "Lorg/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap;", class "Lorg/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap;"
dfs.provided.aliasmap.inmemory.batch-size 500
dfs.provided.aliasmap.inmemory.dnrpc-address "0.0.0.0:50200"
dfs.provided.aliasmap.leveldb.path
dfs.provided.aliasmap.load.retries 0
dfs.provided.aliasmap.text.codec
dfs.provided.aliasmap.text.delimiter ","
dfs.provided.aliasmap.text.read.file "file:///tmp/blocks.csv"
dfs.provided.aliasmap.text.write.dir $r4
dfs.provided.storage.id "DS-PROVIDED"
dfs.quota.by.storage.type.enabled true
dfs.replication 3
dfs.replication.max 512
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms 60000
dfs.storage.policy.enabled true
dfs.trustedchannel.resolver.class class "Lorg/apache/hadoop/hdfs/protocol/datatransfer/TrustedChannelResolver;", class "Lorg/apache/hadoop/hdfs/protocol/datatransfer/TrustedChannelResolver;"
dfs.use.dfs.network.topology true
dfs.user.home.dir.prefix "/user"
dfs.web.authentication.kerberos.keytab
dfs.webhdfs.acl.provider.permission.pattern "^(default:
dfs.webhdfs.oauth2.access.token.provider class "Lorg/apache/hadoop/hdfs/web/oauth2/ConfCredentialBasedAccessTokenProvider;", class "Lorg/apache/hadoop/hdfs/web/oauth2/AccessTokenProvider;"
dfs.webhdfs.oauth2.enabled false
dfs.webhdfs.rest-csrf.custom-header "X-XSRF-HEADER"
dfs.webhdfs.rest-csrf.enabled false
dfs.webhdfs.socket.connect-timeout 60000L, $r5
dfs.webhdfs.socket.read-timeout 60000L, $r6
dfs.webhdfs.user.provider.user.pattern "^[A-Za-z_][A-Za-z0-9._-]*[$]?$"
dfs.xframe.enabled true
dfs.xframe.value "SAMEORIGIN"
