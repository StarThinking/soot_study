dfs.balancer.address "0.0.0.0:0"
dfs.balancer.block-move.timeout 0
dfs.balancer.keytab.enabled false
dfs.balancer.max-iteration-time 1200000L
dfs.balancer.max-no-move-interval 60000
dfs.block.access.token.protobuf.enable false
dfs.block.placement.ec.classname $r11, class "Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy;"
dfs.block.replicator.classname $r7, class "Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy;"
dfs.blocksize 134217728L
dfs.bytes-per-checksum 512
dfs.checksum.combine.mode "MD5MD5CRC"
dfs.checksum.type "CRC32C"
dfs.client.block.write.locateFollowingBlock.initial.delay.ms 400
dfs.client.block.write.locateFollowingBlock.retries 5
dfs.client.block.write.replace-datanode-on-failure.best-effort false
dfs.client.block.write.replace-datanode-on-failure.enable true
dfs.client.block.write.replace-datanode-on-failure.min-replication 0
dfs.client.block.write.replace-datanode-on-failure.policy "DEFAULT"
dfs.client.block.write.retries 3
dfs.client.cached.conn.retry 3
dfs.client.cache.drop.behind.reads
dfs.client.cache.drop.behind.reads false
dfs.client.cache.drop.behind.writes
dfs.client.cache.drop.behind.writes false
dfs.client.cache.readahead
dfs.client.cache.readahead 0L
dfs.client.context "default"
dfs.client.datanode-restart.timeout 30L, $r7
dfs.client.domain.socket.data.traffic false
dfs.client.failover.max.attempts 15
dfs.client.failover.sleep.base.millis 500
dfs.client.failover.sleep.max.millis 15000
dfs.client.hedged.read.threadpool.size 0
dfs.client.hedged.read.threshold.millis 500L
dfs.client.https.need-auth false
dfs.client.key.provider.cache.expiry $l3
dfs.client.local.interfaces
dfs.client.max.block.acquire.failures 3
dfs.client.mmap.cache.size 256
dfs.client.mmap.cache.timeout.ms 3600000L
dfs.client.mmap.enabled true
dfs.client.mmap.retry.timeout.ms 300000L
dfs.client.read.prefetch.size $l23
dfs.client.read.shortcircuit.buffer.size 1048576
dfs.client.read.shortcircuit.metrics.sampling.percentage 0
dfs.client.read.short.circuit.replica.stale.threshold.ms 1800000L
dfs.client.read.shortcircuit.skip.checksum false
dfs.client.read.shortcircuit.streams.cache.expiry.ms 300000L
dfs.client.read.shortcircuit.streams.cache.size 256
dfs.client.read.striped.threadpool.size 18
dfs.client.replica.accessor.builder.classes
dfs.client.retry.interval-ms.get-last-block-length 4000
dfs.client.retry.max.attempts 10
dfs.client.retry.times.get-last-block-length 3
dfs.client.retry.window.base 3000
dfs.client.server-defaults.validity.period.ms $l7
dfs.client.slow.io.warning.threshold.ms 30000L
dfs.client.socketcache.capacity 16
dfs.client.socketcache.expiryMsec 3000L
dfs.client.socket.send.buffer.size 0
dfs.client.socket-timeout 60000
dfs.client.test.drop.namenode.response.number 0
dfs.client.use.datanode.hostname false
dfs.client.use.legacy.blockreader.local false
dfs.client.write.byte-array-manager.count-limit 2048
dfs.client.write.byte-array-manager.count-reset-time-period-ms 10000L
dfs.client.write.byte-array-manager.count-threshold 128
dfs.client.write.byte-array-manager.enabled false
dfs.client.write.exclude.nodes.cache.expiry.interval.millis 600000L
dfs.client.write.max-packets-in-flight 80
dfs.client-write-packet-size 65536
dfs.cluster.administrators " "
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction 0.75F
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold 10737418240L
dfs.datanode.balance.max.concurrent.moves 50
dfs.datanode.block.id.layout.upgrade.threads 12
dfs.datanode.block-pinning.enabled false
dfs.datanode.cached-dfsused.check.interval.ms 600000L
dfs.datanode.cache.revocation.polling.ms 500L
dfs.datanode.cache.revocation.timeout.ms 900000L
dfs.datanode.data.dir
dfs.datanode.data.dir.perm "700"
dfs.datanode.directoryscan.interval 21600L, $r3
dfs.datanode.directoryscan.interval 21600L, $r8
dfs.datanode.directoryscan.threads 1
dfs.datanode.directoryscan.throttle.limit.ms.per.sec 1000
dfs.datanode.duplicate.replica.deletion true
dfs.datanode.du.reserved.calculator $r2, class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator;"
dfs.datanode.ec.reconstruction.stripedread.buffer.size 65536
dfs.datanode.ec.reconstruction.stripedread.timeout.millis 5000
dfs.datanode.enable.fileio.fault.injection false
dfs.datanode.fileio.profiling.sampling.percentage 0
dfs.datanode.fsdatasetcache.max.threads.per.volume 4
dfs.datanode.fsdataset.factory class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetFactory;", class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi$Factory;"
dfs.datanode.fsdataset.volume.choosing.policy class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/RoundRobinVolumeChoosingPolicy;", class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/VolumeChoosingPolicy;"
dfs.datanode.ipc.address "0.0.0.0:9867"
dfs.datanode.kerberos.principal ""
dfs.datanode.lazywriter.interval.sec 60
dfs.datanode.parallel.volumes.load.threads.num i0
dfs.datanode.ram.disk.replica.tracker $r4, class "Lorg/apache/hadoop/hdfs/server/datanode/fsdataset/impl/RamDiskReplicaTracker;"
dfs.datanode.socket.write.timeout 480000
dfs.datanode.startup $r3
dfs.datanode.volumes.replica-add.threadpool.size i1
dfs.datatransfer.client.fixedBlackList.file r4
dfs.datatransfer.client.fixedwhitelist.file r4
dfs.data.transfer.client.tcpnodelay true
dfs.datatransfer.client.variableBlackList.cache.secs 3600L
dfs.datatransfer.client.variableBlackList.enable false
dfs.datatransfer.client.variableBlackList.file r5
dfs.datatransfer.client.variablewhitelist.cache.secs 3600L
dfs.datatransfer.client.variablewhitelist.enable false
dfs.datatransfer.client.variablewhitelist.file r5
dfs.data.transfer.protection
dfs.data.transfer.saslproperties.resolver.class r8, class "Lorg/apache/hadoop/security/SaslPropertiesResolver;"
dfs.datatransfer.server.fixedBlackList.file "/etc/hadoop/fixedBlackList"
dfs.datatransfer.server.fixedwhitelist.file "/etc/hadoop/fixedwhitelist"
dfs.datatransfer.server.variableBlackList.cache.secs 3600L
dfs.datatransfer.server.variableBlackList.enable false
dfs.datatransfer.server.variableBlackList.file "/etc/hadoop/blackList"
dfs.datatransfer.server.variablewhitelist.cache.secs 3600L
dfs.datatransfer.server.variablewhitelist.enable false
dfs.datatransfer.server.variablewhitelist.file "/etc/hadoop/whitelist"
dfs.disk.balancer.block.tolerance.percent 10L
dfs.disk.balancer.enabled true
dfs.disk.balancer.max.disk.errors 5L
dfs.disk.balancer.max.disk.throughputInMBperSec 10
dfs.disk.balancer.max.disk.throughputInMBperSec 10L
dfs.disk.balancer.plan.threshold.percent 10.0
dfs.disk.balancer.plan.valid.interval "1d"
dfs.disk.balancer.plan.valid.interval "1d", $r10
dfs.domain.socket.disable.interval.seconds 600L
dfs.domain.socket.path ""
dfs.edit.log.transfer.bandwidthPerSec 0L
dfs.edit.log.transfer.timeout 30000
dfs.encrypt.data.transfer.algorithm
dfs.encrypt.data.transfer.cipher.key.bitlength 128
dfs.encrypt.data.transfer.cipher.suites
dfs.federation.router.admin-address "0.0.0.0:8111"
dfs.federation.router.store.driver.file.directory
dfs.federation.router.store.driver.fs.path
dfs.federation.router.store.driver.zk.parent-path "/hdfs-federation"
dfs.federation.router.store.serializer $r2, class "Lorg/apache/hadoop/hdfs/server/federation/store/driver/StateStoreSerializer;"
dfs.ha.automatic-failover.enabled false
dfs.ha.log-roll.period 120L, $r7
dfs.ha.log-roll.rpc.timeout 20000
dfs.ha.namenode.id
dfs.ha.tail-edits.in-progress false
dfs.ha.tail-edits.max-txns-per-lock 9223372036854775807L
dfs.ha.tail-edits.namenode-retries 3
dfs.ha.tail-edits.period 60L, $r9
dfs.ha.tail-edits.rolledits.timeout 60
dfs.ha.zkfc.nn.http.timeout.ms 20000
dfs.ha.zkfc.port 8019
dfs.heartbeat.interval 3L, $r10
dfs.heartbeat.interval 3L, $r12
dfs.heartbeat.interval 3L, $r5
dfs.heartbeat.interval r3, $r8
dfs.hosts ""
dfs.hosts.exclude ""
dfs.http.client.failover.max.attempts 15
dfs.http.client.failover.sleep.base.millis 500
dfs.http.client.failover.sleep.max.millis 15000
dfs.http.client.retry.max.attempts 10
dfs.http.policy $r3
dfs.https.server.keystore.resource "ssl-server.xml"
dfs.image.compress false
dfs.image.compression.codec "org.apache.hadoop.io.compress.DefaultCodec"
dfs.image.transfer.bandwidthPerSec 0L
dfs.image.transfer-bootstrap-standby.bandwidthPerSec 0L
dfs.image.transfer.chunksize 65536
dfs.image.transfer.timeout 60000
dfs.internal.nameservices
dfs.journalnode.edits.dir "/tmp/hadoop/dfs/journalnode/"
dfs.journalnode.enable.sync true
dfs.journalnode.http-address "0.0.0.0:8480"
dfs.journalnode.http-bind-host
dfs.journalnode.https-address "0.0.0.0:8481"
dfs.journalnode.https-bind-host
dfs.journalnode.rpc-address "0.0.0.0:8485"
dfs.journalnode.rpc-bind-host null
dfs.journalnode.sync.interval 120000L
dfs.lock.suppress.warning.interval 10000L, $r13
dfs.metrics.percentiles.intervals
dfs.metrics.session-id
dfs.mover.address "0.0.0.0:0"
dfs.mover.keytab.enabled false
dfs.mover.max-no-move-interval 60000
dfs.mover.movedWinWidth 5400000L
dfs.mover.moverThreads 1000
dfs.mover.retry.max.attempts 10
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction 0.6F
dfs.namenode.block-placement-policy.default.prefer-local-node true
dfs.namenode.checkpoint.check.period 60L, $r2
dfs.namenode.checkpoint.check.quiet-multiplier 1.5
dfs.namenode.checkpoint.max-retries 3
dfs.namenode.checkpoint.period 3600L, $r28
dfs.namenode.checkpoint.period 3600L, $r3
dfs.namenode.checkpoint.txns 1000000L
dfs.namenode.ec.system.default.policy "RS-6-3-1024k"
dfs.namenode.edits.asynclogging true
dfs.namenode.edits.dir.minimum 1
dfs.namenode.edits.noeditlogchannelflush false
dfs.namenode.inotify.max.events.per.rpc 1000
dfs.namenode.kerberos.principal ""
dfs.namenode.legacy-oiv-image.dir
dfs.namenode.max.extra.edits.segments.retained 10000
dfs.namenode.missing.checkpoint.periods.before.shutdown 3
dfs.namenode.name.dir.restore false
dfs.namenode.num.checkpoints.retained 2
dfs.namenode.num.extra.edits.retained 1000000L
dfs.namenode.redundancy.considerLoad.factor 2.0
dfs.namenode.redundancy.considerLoad true
dfs.namenode.redundancy.interval.seconds 3L, $r11
dfs.namenode.redundancy.interval.seconds 3L, $r13
dfs.namenode.replication.min 1
dfs.namenode.rpc-address
dfs.namenode.servicerpc-address
dfs.namenode.shared.edits.dir
dfs.namenode.stale.datanode.interval 30000L
dfs.namenode.startup $r2
dfs.namenode.support.allow.format true
dfs.namenode.tolerate.heartbeat.multiplier 4
dfs.namenode.upgrade.domain.factor 3
dfs.nameservice.id
dfs.nameservices
dfs.provided.aliasmap.class class "Lorg/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap;", class "Lorg/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap;"
dfs.provided.aliasmap.inmemory.batch-size 500
dfs.provided.aliasmap.inmemory.dnrpc-address "0.0.0.0:50200"
dfs.provided.aliasmap.leveldb.path
dfs.provided.aliasmap.load.retries 0
dfs.provided.aliasmap.text.codec
dfs.provided.aliasmap.text.delimiter ","
dfs.provided.aliasmap.text.read.file "file:///tmp/blocks.csv"
dfs.provided.aliasmap.text.write.dir $r4
dfs.provided.storage.id "DS-PROVIDED"
dfs.replication 3
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms 60000
dfs.trustedchannel.resolver.class class "Lorg/apache/hadoop/hdfs/protocol/datatransfer/TrustedChannelResolver;", class "Lorg/apache/hadoop/hdfs/protocol/datatransfer/TrustedChannelResolver;"
dfs.user.home.dir.prefix "/user"
dfs.web.authentication.kerberos.keytab
dfs.webhdfs.acl.provider.permission.pattern "^(default:
dfs.webhdfs.oauth2.access.token.provider class "Lorg/apache/hadoop/hdfs/web/oauth2/ConfCredentialBasedAccessTokenProvider;", class "Lorg/apache/hadoop/hdfs/web/oauth2/AccessTokenProvider;"
dfs.webhdfs.oauth2.enabled false
dfs.webhdfs.rest-csrf.custom-header "X-XSRF-HEADER"
dfs.webhdfs.rest-csrf.enabled false
dfs.webhdfs.socket.connect-timeout 60000L, $r5
dfs.webhdfs.socket.read-timeout 60000L, $r6
dfs.webhdfs.user.provider.user.pattern "^[A-Za-z_][A-Za-z0-9._-]*[$]?$"
