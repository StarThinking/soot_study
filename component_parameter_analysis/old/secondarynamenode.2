edgeAnalysis for function get [java.lang.String]
edgeAnalysis for function get [java.lang.String, java.lang.String]
edgeAnalysis for function getInt
edgeAnalysis for function getInts
edgeAnalysis for function getLong
edgeAnalysis for function getLongBytes
edgeAnalysis for function getHexDigits
edgeAnalysis for function getFloat
edgeAnalysis for function getDouble
edgeAnalysis for function getBoolean
Results: parameters statically used on component org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
57 parameters read from function getLong:
dfs.ha.tail-edits.max-txns-per-lock 9223372036854775807L
dfs.disk.balancer.block.tolerance.percent 10L
dfs.namenode.write-lock-reporting-threshold-ms 5000L
dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold 10737418240L
dfs.datatransfer.server.variablewhitelist.cache.secs 3600L
dfs.content-summary.sleep-microsec 500L
dfs.namenode.max-lock-hold-to-release-lease-ms 25L
dfs.namenode.max-num-blocks-to-log 1000L
dfs.namenode.storageinfo.defragment.interval.ms 600000L
dfs.namenode.stale.datanode.interval 30000L
dfs.namenode.path.based.cache.retry.interval.ms 30000L
dfs.namenode.max.objects 0L
dfs.edit.log.transfer.bandwidthPerSec 0L
dfs.client.server-defaults.validity.period.ms $l7
dfs.block.access.token.lifetime 600L
dfs.namenode.fs-limits.max-blocks-per-file 10000L
dfs.disk.balancer.max.disk.errors 5L
dfs.journalnode.sync.interval 120000L
dfs.client.mmap.retry.timeout.ms 300000L
dfs.client.write.byte-array-manager.count-reset-time-period-ms 10000L
dfs.datatransfer.server.variableBlackList.cache.secs 3600L
dfs.disk.balancer.max.disk.throughputInMBperSec 10L
dfs.client.read.shortcircuit.streams.cache.expiry.ms 300000L
dfs.namenode.read-lock-reporting-threshold-ms 5000L
dfs.domain.socket.disable.interval.seconds 600L
dfs.client.slow.io.warning.threshold.ms 30000L
dfs.client.write.exclude.nodes.cache.expiry.interval.millis 600000L
dfs.datanode.cache.revocation.polling.ms 500L
dfs.datatransfer.client.variablewhitelist.cache.secs 3600L
dfs.client.socketcache.expiryMsec 3000L
dfs.namenode.num.extra.edits.retained 1000000L
dfs.datatransfer.client.variableBlackList.cache.secs 3600L
dfs.client.key.provider.cache.expiry $l3
dfs.namenode.startup.delay.block.deletion.sec 0L
dfs.namenode.delegation.token.max-lifetime 604800000L
dfs.namenode.storageinfo.defragment.timeout.ms 4L
dfs.namenode.full.block.report.lease.length.ms 300000L
dfs.namenode.delegation.token.renew-interval 86400000L
dfs.namenode.retrycache.expirytime.millis 600000L
dfs.datanode.cache.revocation.timeout.ms 900000L
dfs.namenode.blocks.per.postponedblocks.rescan 10000L
dfs.namenode.fs-limits.min-block-size 1048576L
dfs.client.hedged.read.threshold.millis 500L
dfs.datanode.cached-dfsused.check.interval.ms 600000L
dfs.namenode.lease-recheck-interval-ms 2000L
dfs.client.cache.readahead 0L
dfs.image.transfer-bootstrap-standby.bandwidthPerSec 0L
dfs.client.read.short.circuit.replica.stale.threshold.ms 1800000L
dfs.namenode.accesstime.precision 3600000L
dfs.client.mmap.cache.timeout.ms 3600000L
dfs.namenode.path.based.cache.refresh.interval.ms 30000L
dfs.namenode.delegation.key.update-interval 86400000L
dfs.client.read.prefetch.size $l23
dfs.image.transfer.bandwidthPerSec 0L
dfs.block.access.key.update.interval 600L
dfs.namenode.checkpoint.txns 1000000L
dfs.namenode.resource.check.interval 5000L

108 parameters read from function getInt:
dfs.client.read.shortcircuit.buffer.size 1048576
dfs.client.failover.sleep.base.millis 500
dfs.namenode.fs-limits.max-xattrs-per-inode 32
dfs.namenode.edekcacheloader.interval.ms 1000
dfs.http.client.failover.sleep.max.millis 15000
dfs.namenode.reconstruction.pending.timeout-sec 300
dfs.namenode.fs-limits.max-component-length 255
dfs.namenode.upgrade.domain.factor 3
dfs.namenode.max.full.block.report.leases 6
dfs.client-write-packet-size 65536
dfs.namenode.checkpoint.max-retries 3
dfs.namenode.snapshot.skiplist.max.levels 0
dfs.datanode.fsdatasetcache.max.threads.per.volume 4
dfs.client.block.write.retries 3
dfs.namenode.snapshotdiff.listing.limit 1000
dfs.client.read.striped.threadpool.size 18
dfs.client.test.drop.namenode.response.number 0
dfs.namenode.edekcacheloader.initial.delay.ms 3000
dfs.datanode.fileio.profiling.sampling.percentage 0
dfs.namenode.fs-limits.max-directory-items 1048576
dfs.client.hedged.read.threadpool.size 0
dfs.short.circuit.shared.memory.watcher.interrupt.check.ms 60000
dfs.encrypt.data.transfer.cipher.key.bitlength 128
dfs.client.retry.times.get-last-block-length 3
dfs.bytes-per-checksum 512
dfs.namenode.ec.policies.max.cellsize 4194304
dfs.datanode.ec.reconstruction.stripedread.timeout.millis 5000
dfs.client.read.shortcircuit.metrics.sampling.percentage 0
dfs.namenode.reencrypt.edek.threads 10
dfs.namenode.replication.work.multiplier.per.iteration 2
dfs.image.transfer.timeout 60000
dfs.block.misreplication.processing.limit 10000
dfs.ha.zkfc.port 8019
dfs.client.block.write.locateFollowingBlock.initial.delay.ms 400
dfs.replication 3
dfs.namenode.safemode.replication.min i0
dfs.namenode.heartbeat.recheck-interval 300000
dfs.namenode.stale.datanode.minimum.interval 3
dfs.datanode.ec.reconstruction.stripedread.buffer.size 65536
dfs.datanode.directoryscan.throttle.limit.ms.per.sec 1000
dfs.ha.log-roll.rpc.timeout 20000
dfs.namenode.safemode.min.datanodes 0
dfs.namenode.snapshot.skiplist.interval 10
dfs.ls.limit 1000
dfs.datanode.block.id.layout.upgrade.threads 12
dfs.namenode.num.checkpoints.retained 2
dfs.client.block.write.locateFollowingBlock.retries 5
dfs.namenode.reencrypt.batch.size 1000
dfs.client.socket.send.buffer.size 0
dfs.block.invalidate.limit 1000
dfs.datanode.lazywriter.interval.sec 60
dfs.namenode.top.window.num.buckets 10
dfs.namenode.inotify.max.events.per.rpc 1000
dfs.namenode.replication.max-streams-hard-limit 4
dfs.namenode.file.close.num-committed-allowed 0
dfs.client.failover.max.attempts 15
dfs.client.retry.window.base 3000
dfs.disk.balancer.max.disk.throughputInMBperSec 10
dfs.namenode.maintenance.replication.min 1
dfs.ha.tail-edits.rolledits.timeout 60
dfs.provided.aliasmap.inmemory.batch-size 500
dfs.client.block.write.replace-datanode-on-failure.min-replication 0
dfs.namenode.list.cache.directives.num.responses 100
dfs.namenode.list.reencryption.status.num.responses 100
dfs.datanode.directoryscan.threads 1
dfs.http.client.retry.max.attempts 10
dfs.namenode.tolerate.heartbeat.multiplier 4
dfs.replication.max 512
dfs.client.write.byte-array-manager.count-threshold 128
dfs.client.cached.conn.retry 3
dfs.namenode.fs-limits.max-xattr-size 16384
dfs.http.client.failover.max.attempts 15
dfs.provided.aliasmap.load.retries 0
dfs.client.socket-timeout 60000
dfs.namenode.top.num.users 10
dfs.namenode.max.extra.edits.segments.retained 10000
dfs.client.write.byte-array-manager.count-limit 2048
dfs.namenode.replication.max-streams 2
dfs.ha.zkfc.nn.http.timeout.ms 20000
dfs.corruptfilesreturned.max 500
dfs.datanode.volumes.replica-add.threadpool.size i1
dfs.namenode.quota.init-threads 4
dfs.namenode.list.openfiles.num.responses 1000
dfs.image.transfer.chunksize 65536
dfs.namenode.snapshot.max.limit 65536
dfs.namenode.name.cache.threshold 10
dfs.client.socketcache.capacity 16
dfs.namenode.list.cache.pools.num.responses 100
dfs.client.write.max-packets-in-flight 80
dfs.namenode.edit.log.autoroll.check.interval.ms 300000
dfs.client.max.block.acquire.failures 3
dfs.content-summary.limit 5000
dfs.client.read.shortcircuit.streams.cache.size 256
dfs.namenode.list.encryption.zones.num.responses 100
dfs.namenode.lazypersist.file.scrub.interval.sec 300
dfs.namenode.edits.dir.minimum 1
dfs.client.retry.interval-ms.get-last-block-length 4000
dfs.datanode.parallel.volumes.load.threads.num i0
dfs.client.failover.sleep.max.millis 15000
dfs.client.mmap.cache.size 256
dfs.namenode.block.deletion.increment 1000
dfs.ha.tail-edits.namenode-retries 3
dfs.namenode.replication.min 1
dfs.edit.log.transfer.timeout 30000
dfs.client.retry.max.attempts 10
dfs.datanode.socket.write.timeout 480000
dfs.http.client.failover.sleep.base.millis 500
dfs.namenode.max-corrupt-file-blocks-returned 100

1 parameters read from function getLongBytes:
dfs.blocksize 134217728L

0 parameters read from function getHexDigits:

5 parameters read from function getDouble:
dfs.namenode.reencrypt.throttle.limit.updater.ratio 1.0
dfs.namenode.reencrypt.throttle.limit.handler.ratio 1.0
dfs.namenode.storageinfo.defragment.ratio 0.75
dfs.namenode.redundancy.considerLoad.factor 2.0
dfs.namenode.checkpoint.check.quiet-multiplier 1.5

1 parameters read from function getInts:
dfs.metrics.percentiles.intervals

60 parameters read from function getBoolean:
dfs.client.block.write.replace-datanode-on-failure.best-effort 0
dfs.namenode.posix.acl.inheritance.enabled 1
dfs.namenode.lock.detailed-metrics.enabled 0
dfs.datatransfer.client.variablewhitelist.enable 0
dfs.namenode.provided.enabled 0
dfs.namenode.snapshot.skip.capture.accesstime-only-change 0
dfs.namenode.delegation.token.always-use 0
dfs.client.domain.socket.data.traffic 0
dfs.client.write.byte-array-manager.enabled 0
dfs.storage.policy.enabled 1
dfs.client.block.write.replace-datanode-on-failure.enable 1
dfs.datatransfer.server.variableBlackList.enable 0
dfs.permissions.enabled 1
dfs.namenode.edits.noeditlogchannelflush 0
dfs.ha.automatic-failover.enabled 0
dfs.datanode.enable.fileio.fault.injection 0
dfs.client.https.need-auth 0
dfs.datanode.block-pinning.enabled 0
dfs.webhdfs.oauth2.enabled 0
dfs.webhdfs.rest-csrf.enabled 0
dfs.namenode.avoid.write.stale.datanode 0
dfs.namenode.name.dir.restore 0
dfs.disk.balancer.enabled 1
dfs.encrypt.data.transfer 0
dfs.client.read.shortcircuit.skip.checksum 0
dfs.journalnode.enable.sync 1
dfs.namenode.snapshotdiff.allow.snap-root-descendant 1
dfs.namenode.avoid.read.stale.datanode 0
dfs.image.string-tables.expanded 0
dfs.client.use.datanode.hostname 0
dfs.namenode.acls.enabled 0
dfs.quota.by.storage.type.enabled 1
dfs.xframe.enabled 1
dfs.datatransfer.client.variableBlackList.enable 0
dfs.ha.standby.checkpoints 1
dfs.namenode.redundancy.considerLoad 1
dfs.namenode.fslock.fair 1
dfs.namenode.datanode.registration.ip-hostname-check 1
dfs.datanode.duplicate.replica.deletion 1
dfs.namenode.audit.log.async 0
dfs.namenode.audit.log.token.tracking.id 0
dfs.data.transfer.client.tcpnodelay 1
dfs.image.compress 0
dfs.use.dfs.network.topology 1
dfs.datatransfer.server.variablewhitelist.enable 0
dfs.namenode.enable.retrycache 1
dfs.namenode.edits.asynclogging 1
dfs.client.cache.drop.behind.reads 0
dfs.namenode.snapshot.capture.openfiles 0
dfs.block.access.token.enable 0
dfs.namenode.xattrs.enabled 1
dfs.namenode.block-placement-policy.default.prefer-local-node 1
dfs.namenode.reject-unresolved-dn-topology-mapping 0
dfs.ha.tail-edits.in-progress 0
dfs.client.mmap.enabled 1
dfs.datanode.peer.stats.enabled 0
dfs.client.use.legacy.blockreader.local 0
dfs.client.cache.drop.behind.writes 0
dfs.block.access.token.protobuf.enable 0
dfs.namenode.top.enabled 1

22 parameters read from function get1:
dfs.client.cache.drop.behind.writes
dfs.namenode.shared.edits.dir
dfs.namenode.legacy-oiv-image.dir
dfs.encrypt.data.transfer.cipher.suites
dfs.ha.namenode.id
dfs.federation.router.store.driver.fs.path
dfs.federation.router.store.driver.file.directory
dfs.nameservices
dfs.client.cache.readahead
dfs.client.cache.drop.behind.reads
dfs.namenode.top.windows.minutes
dfs.namenode.top.num.users
dfs.provided.aliasmap.text.codec
dfs.data.transfer.protection
dfs.encrypt.data.transfer.algorithm
dfs.provided.aliasmap.leveldb.path
dfs.web.authentication.kerberos.keytab
dfs.nameservice.id
dfs.namenode.rpc-address
dfs.namenode.top.window.num.buckets
dfs.datanode.data.dir
dfs.metrics.session-id

9 parameters read from function getFloat:
dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction 0.75F
dfs.namenode.invalidate.work.pct.per.iteration 0.32F
dfs.namenode.safemode.threshold-pct 0.999F
dfs.namenode.edit.log.autoroll.multiplier.threshold 2.0F
dfs.namenode.path.based.cache.block.map.allocation.percent 0.25F
dfs.namenode.replqueue.threshold-pct $f1
dfs.namenode.write.stale.datanode.ratio 0.5F
dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction 0.6F
dfs.namenode.retrycache.heap.percent 0.03F

33 parameters read from function get2:
dfs.namenode.kerberos.principal ""
dfs.federation.router.store.driver.zk.parent-path "/hdfs-federation"
dfs.http.policy $r3
dfs.client.context "default"
dfs.user.home.dir.prefix "/user"
dfs.datatransfer.server.variablewhitelist.file "/etc/hadoop/whitelist"
dfs.datatransfer.client.variablewhitelist.file r5
dfs.datanode.data.dir.perm "700"
dfs.datatransfer.client.variableBlackList.file r5
dfs.webhdfs.acl.provider.permission.pattern "^(default:
dfs.datatransfer.client.fixedBlackList.file r4
dfs.permissions.superusergroup "supergroup"
dfs.datatransfer.client.fixedwhitelist.file r4
dfs.journalnode.edits.dir "/tmp/hadoop/dfs/journalnode/"
dfs.checksum.type "CRC32C"
dfs.disk.balancer.plan.valid.interval "1d"
dfs.provided.aliasmap.text.delimiter ","
dfs.checksum.combine.mode "MD5MD5CRC"
dfs.namenode.startup $r2
dfs.datatransfer.server.variableBlackList.file "/etc/hadoop/blackList"
dfs.hosts ""
dfs.datatransfer.server.fixedBlackList.file "/etc/hadoop/fixedBlackList"
dfs.datatransfer.server.fixedwhitelist.file "/etc/hadoop/fixedwhitelist"
dfs.webhdfs.user.provider.user.pattern "^[A-Za-z_][A-Za-z0-9._-]*[$]?$"
dfs.client.block.write.replace-datanode-on-failure.policy "DEFAULT"
dfs.hosts.exclude ""
dfs.provided.aliasmap.text.read.file "file:///tmp/blocks.csv"
dfs.provided.aliasmap.text.write.dir $r4
dfs.cluster.administrators " "
dfs.provided.storage.id "DS-PROVIDED"
dfs.image.compression.codec "org.apache.hadoop.io.compress.DefaultCodec"
dfs.datanode.startup $r3
dfs.https.server.keystore.resource "ssl-server.xml"

